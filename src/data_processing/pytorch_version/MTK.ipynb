{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad32acbd-38dc-46ba-8fb9-9cdca5cfb6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from libauc.losses import AUCMLoss \n",
    "from libauc.optimizers import PESG \n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import Pdb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "# LEARN_RATE = 0.1\n",
    "LEARN_RATE = 0.001\n",
    "\n",
    "MARGIN = 1.0\n",
    "EPOCH_DECAY = 0.003\n",
    "WEIGHT_DECAY = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea67031-5374-44af-82c6-d3c5be21933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Diagnosis', 'FEV1', 'FEV1/FVC', 'FEF2575', 'FEV1_pred',\n",
      "       'FEV1/FVC_pred', 'FEF2575_pred'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Trial', 'Age', 'Sex', 'Height', 'Weight'], dtype='object')\n",
      "# of samples: 121\n",
      "55 66\n"
     ]
    }
   ],
   "source": [
    "# Build dataset from csv files\n",
    "class AwareDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_data, csv_outcome, csv_verbose, root_dir, target_classes=None, transform=None):\n",
    "        self.data_raw = pd.read_csv(csv_data, header=None)\n",
    "        self.data_out = pd.read_csv(csv_outcome)\n",
    "        self.data_verb = pd.read_csv(csv_verbose)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        if target_classes != None:\n",
    "            idx = False\n",
    "            for i in target_classes:\n",
    "                idx |= (self.data_out['Diagnosis']==i)\n",
    "                for col in self.data_out.columns:\n",
    "                    idx &= (~self.data_out[col].isna())\n",
    "            self.data_raw = self.data_raw[idx].reset_index(drop=True)\n",
    "            self.data_out = self.data_out[idx].reset_index(drop=True)\n",
    "            self.data_verb = self.data_verb[idx].reset_index(drop=True)\n",
    "            print(self.data_out.columns)\n",
    "            print(self.data_verb.columns)\n",
    "            print('# of samples:', len(self.data_raw))\n",
    "        \n",
    "#         idx_remove = np.where(self.data_verb['Age']>18)[0].tolist()\n",
    "#         self.data_raw = self.data_raw.drop(idx_remove).reset_index(drop=True)\n",
    "#         self.data_out = self.data_out.drop(idx_remove).reset_index(drop=True)\n",
    "#         self.data_verb = self.data_verb.drop(idx_remove).reset_index(drop=True)\n",
    "        \n",
    "        n_pos = np.sum(self.data_out['Diagnosis']==2)\n",
    "        n_neg = np.sum(self.data_out['Diagnosis']==0)\n",
    "        print(n_pos,n_neg)\n",
    "        \n",
    "        self.data_out['Diagnosis'] = self.data_out['Diagnosis']/2\n",
    "        \n",
    "#         idx_remove = np.where(self.data_out['Diagnosis']==1)[0].tolist()\n",
    "#         idx_remove = random.sample(idx_remove, n_pos-n_neg)\n",
    "#         self.data_raw = self.data_raw.drop(idx_remove).reset_index(drop=True)\n",
    "#         self.data_out = self.data_out.drop(idx_remove).reset_index(drop=True)\n",
    "#         self.data_verb = self.data_verb.drop(idx_remove).reset_index(drop=True)\n",
    "        \n",
    "        if len(self.data_raw) != len(self.data_out) or len(self.data_raw) != len(self.data_verb):\n",
    "            raise Exception(\"Inconsistent data length\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_raw)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        data = self.data_raw.iloc[idx, 34:118].values.astype('float32')\n",
    "        data = (data-np.mean(data))/np.std(data)\n",
    "        target = self.data_out.iloc[idx, :].values.astype('float32')\n",
    "        verbose = self.data_verb.iloc[idx, :].values.astype('float32')\n",
    "\n",
    "        return data, target, verbose\n",
    "\n",
    "dataset = AwareDataset(csv_data = 'data/exhale_data_v6_ave.csv',\n",
    "                       csv_outcome = 'data/exhale_outcome_v6_ave.csv',\n",
    "                       csv_verbose = 'data/exhale_verbose_v6_ave.csv',\n",
    "                       root_dir = 'data/',\n",
    "                       target_classes = [0,2])\n",
    "\n",
    "# dataiter = iter(trainloader)\n",
    "# inputs, labels, info = dataiter.next()\n",
    "# print(inputs.size())\n",
    "# print(labels[0])\n",
    "# plt.plot(inputs[0])\n",
    "# plt.ylim([-5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc00a66-94fd-47ee-9b33-cea7e4be4f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (regressor1): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      "  (regressor2): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=2, bias=True)\n",
      "    (5): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.MTK import Net\n",
    "model = Net()\n",
    "print(model)\n",
    "model.to(device)\n",
    "if device == 'cuda':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "encoder = nn.Sequential(\n",
    "    nn.Linear(84, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 48),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(48, 48))\n",
    "encoder.load_state_dict(torch.load('./checkpoint/encoder_0.04.pth')['net'])\n",
    "encoder.to(device)\n",
    "if device == 'cuda':\n",
    "    encoder = torch.nn.DataParallel(encoder)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458befbd-8922-4019-ac15-c77e6cc38e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion1 = AUCMLoss()\n",
    "# criterion2 = nn.MSELoss()\n",
    "# optimizer = PESG(model, \n",
    "#                  loss_fn=criterion1,\n",
    "#                  lr=LEARN_RATE,\n",
    "#                  momentum=0.9,\n",
    "#                  margin=MARGIN, \n",
    "#                  epoch_decay=EPOCH_DECAY, \n",
    "#                  weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss(weight=torch.Tensor([1, 1]).to(device))\n",
    "# criterion1 = nn.CrossEntropyLoss(weight=torch.Tensor([2.5, 0.625]).to(device))\n",
    "criterion2 = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARN_RATE)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def train(epoch):\n",
    "    clear_output(wait=False)\n",
    "    print('Epoch: %d | TRAIN' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, labels, info) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        inputs = encoder(inputs)\n",
    "        outputs_pred, outputs_fev1, outputs_fev1_fvc = model(inputs)\n",
    "        \n",
    "        loss1 = criterion1(outputs_pred, labels[:,0].long())\n",
    "        loss2 = criterion2(outputs_fev1, labels[:,4])\n",
    "        loss3 = criterion2(outputs_fev1_fvc, labels[:,5])\n",
    "        loss = loss1 + (loss2 + loss3)*1e-3\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs_pred, 1)\n",
    "        total += labels.size(0)\n",
    "        train_correct += torch.sum(preds == labels[:,0].data)\n",
    "\n",
    "        print('Batch: %d/%d | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "              % (batch_idx+1, len(trainloader), train_loss/(batch_idx+1), 100.*train_correct/total, train_correct, total), end='\\r')\n",
    "        \n",
    "    writer.add_scalar('Loss/train', train_loss/(batch_idx+1), epoch)\n",
    "    writer.add_scalar('Acc/train', train_correct/total, epoch)\n",
    "        \n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    best_acc = 0\n",
    "    # clear_output(wait=False)\n",
    "    print('Epoch: %d | TEST' % epoch)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels, info) in enumerate(testloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = encoder(inputs)\n",
    "            outputs_pred, outputs_fev1, outputs_fev1_fvc = model(inputs)\n",
    "\n",
    "            loss1 = criterion1(outputs_pred, labels[:,0].long())\n",
    "            loss2 = criterion2(outputs_fev1, labels[:,4])\n",
    "            loss3 = criterion2(outputs_fev1_fvc, labels[:,5])\n",
    "            loss = loss1 + (loss2 + loss3)*1e-3\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, preds = torch.max(outputs_pred, 1)\n",
    "            total += labels.size(0)\n",
    "            test_correct += torch.sum(preds == labels[:,0].data)\n",
    "\n",
    "            print('Batch: %d/%d | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                  % (batch_idx+1, len(testloader), test_loss/(batch_idx+1), 100.*test_correct/total, test_correct, total), end='\\r')\n",
    "        \n",
    "    writer.add_scalar('Loss/test', test_loss/(batch_idx+1), epoch)\n",
    "    writer.add_scalar('Acc/test', test_correct/total, epoch)\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*test_correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving.. | Acc:%.3f%%\\n' % acc)\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt_MTK.pth')\n",
    "        best_acc = acc\n",
    "\n",
    "metrics = {'Accuracy':[], \n",
    "          'BalancedAccuracy':[],\n",
    "          'Precision':[],\n",
    "          'Recall':[],\n",
    "          'Specificity':[],\n",
    "          'AUROC':[]}\n",
    "\n",
    "predictions = {'Score0':[], 'Score1':[], 'Prediction':[], 'FEV1_est':[], 'FEV1/FVC_est':[],\n",
    "               'Diagnosis':[], 'FEV1':[], 'FEV1/FVC':[], 'FEF2575':[],\n",
    "               'FEV1_pred':[], 'FEV1/FVC_pred':[], 'FEF2575_pred':[],\n",
    "               'ID':[], 'Trial':[], 'Age':[], 'Sex':[], 'Height':[], 'Weight':[]}               \n",
    "\n",
    "def evaluate(fold):\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels, info) in enumerate(testloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = encoder(inputs)\n",
    "            outputs_pred, outputs_fev1, outputs_fev1_fvc = model(inputs)\n",
    "            _, preds = torch.max(outputs_pred, 1)\n",
    "            tn, fp, fn, tp = confusion_matrix(labels[:,0].cpu(), preds.cpu()).ravel()\n",
    "            \n",
    "            metrics['Accuracy'].append(accuracy_score(labels[:,0].cpu(), preds.cpu()))\n",
    "            metrics['BalancedAccuracy'].append(balanced_accuracy_score(labels[:,0].cpu(), preds.cpu()))\n",
    "            metrics['Precision'].append(precision_score(labels[:,0].cpu(), preds.cpu()))\n",
    "            metrics['Recall'].append(recall_score(labels[:,0].cpu(), preds.cpu()))\n",
    "            metrics['Specificity'].append(tn/(tn+fp))\n",
    "            metrics['AUROC'].append(roc_auc_score(labels[:,0].cpu(), outputs_pred[:,1].cpu()))\n",
    "            \n",
    "            print(outputs_pred[:,0].cpu().numpy())\n",
    "            predictions['Score0'].extend(outputs_pred[:,0].cpu().numpy())\n",
    "            predictions['Score1'].extend(outputs_pred[:,1].cpu().numpy())\n",
    "            predictions['Prediction'].extend(preds.cpu().numpy())\n",
    "            predictions['Diagnosis'].extend(labels[:,0].long().cpu().numpy())\n",
    "            predictions['FEV1_est'].extend(outputs_fev1[:,0].cpu().numpy())\n",
    "            predictions['FEV1/FVC_est'].extend(outputs_fev1_fvc[:,0].cpu().numpy())\n",
    "            predictions['FEV1'].extend(labels[:,1].cpu().numpy())\n",
    "            predictions['FEV1/FVC'].extend(labels[:,2].cpu().numpy())\n",
    "            predictions['FEF2575'].extend(labels[:,3].cpu().numpy())\n",
    "            predictions['FEV1_pred'].extend(labels[:,4].cpu().numpy())\n",
    "            predictions['FEV1/FVC_pred'].extend(labels[:,5].cpu().numpy())\n",
    "            predictions['FEF2575_pred'].extend(labels[:,6].cpu().numpy())\n",
    "            predictions['ID'].extend(info[:,0].cpu().numpy())\n",
    "            predictions['Trial'].extend(info[:,1].cpu().numpy())\n",
    "            predictions['Age'].extend(info[:,2].cpu().numpy())\n",
    "            predictions['Sex'].extend(info[:,3].cpu().numpy())\n",
    "            predictions['Height'].extend(info[:,4].cpu().numpy())\n",
    "            predictions['Weight'].extend(info[:,5].cpu().numpy())\n",
    "            \n",
    "#             print('Fold: ', fold)\n",
    "#             print(torch.cat((preds,labels[:,0]), 2))\n",
    "#             print(confusion_matrix(labels[:,0].cpu(), preds.cpu()))\n",
    "#             print('Accuracy:          %.2f' % accuracy_score(labels[:,0].cpu(), preds.cpu()))\n",
    "#             print('Balanced Accuracy: %.2f' % balanced_accuracy_score(labels[:,0].cpu(), preds.cpu()))\n",
    "#             print('Precision:         %.2f' % precision_score(labels[:,0].cpu(), preds.cpu()))\n",
    "#             print('Recall:            %.2f' % recall_score(labels[:,0].cpu(), preds.cpu()))\n",
    "#             print('AUROC:             %.2f' % roc_auc_score(labels[:,0].cpu(), outputs_pred[:,1].cpu()))\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "        \n",
    "def subject_accuracy(output, labels, ids):\n",
    "    unique_ids = torch.unique(ids)\n",
    "    for i in unique_ids:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e29f750-af9d-4e10-8e7b-fbe5ad2f778b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199 | TRAIN\n",
      "Epoch: 199 | TEST: 1.026 | Acc: 69.072% (67/97)\n",
      "Saving.. | Acc:62.500%46 | Acc: 62.500% (15/24)\n",
      "\n",
      "[0.4225707  0.55744696 0.32489306 0.17405713 0.2179031  0.64161175\n",
      " 0.43087277 0.6094339  0.46348938 0.7344333  0.73258007 0.23296742\n",
      " 0.28449577 0.61162853 0.35487267 0.4861696  0.63921314 0.53512454\n",
      " 0.42013776 0.37249818 0.51960915 0.25033778 0.45208523 0.5593583 ]\n",
      "{'Accuracy': [0.6, 0.625, 0.5833333333333334, 0.5, 0.625], 'BalancedAccuracy': [0.5844155844155844, 0.5979020979020979, 0.5664335664335665, 0.5104895104895105, 0.6328671328671329], 'Precision': [0.5555555555555556, 0.75, 0.5714285714285714, 0.4666666666666667, 0.5714285714285714], 'Recall': [0.45454545454545453, 0.2727272727272727, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273], 'Specificity': [0.7142857142857143, 0.9230769230769231, 0.7692307692307693, 0.38461538461538464, 0.5384615384615384], 'AUROC': [0.6818181818181818, 0.7342657342657343, 0.6853146853146853, 0.46153846153846145, 0.6573426573426574]}\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(0,len(dataset)))\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "for i, (train_idx, test_idx) in enumerate(skf.split(idx, dataset.data_out['Diagnosis'])):\n",
    "    model.apply(weight_reset)\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=len(test_idx), sampler=test_sampler)\n",
    "    for epoch in range(200):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        if isinstance(criterion1, AUCMLoss):\n",
    "            optimizer.update_regularizer()\n",
    "        if 'scheduler' in globals():\n",
    "            scheduler.step()\n",
    "    \n",
    "    model.load_state_dict(torch.load('./checkpoint/ckpt_MTK.pth')['net'])\n",
    "\n",
    "    evaluate(i)\n",
    "    print(metrics)\n",
    "    os.rename('./checkpoint/ckpt_MTK.pth', f'./checkpoint/ckpt_MTK_{best_acc:.2f}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29990cd-809a-40b4-9d1b-70eb1c1b5468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy  BalancedAccuracy  Precision    Recall  Specificity     AUROC\n",
      "0  0.600000          0.584416   0.555556  0.454545     0.714286  0.681818\n",
      "1  0.625000          0.597902   0.750000  0.272727     0.923077  0.734266\n",
      "2  0.583333          0.566434   0.571429  0.363636     0.769231  0.685315\n",
      "3  0.500000          0.510490   0.466667  0.636364     0.384615  0.461538\n",
      "4  0.625000          0.632867   0.571429  0.727273     0.538462  0.657343\n",
      "Accuracy            0.586667\n",
      "BalancedAccuracy    0.578422\n",
      "Precision           0.583016\n",
      "Recall              0.490909\n",
      "Specificity         0.665934\n",
      "AUROC               0.644056\n",
      "dtype: float64\n",
      "       Score0    Score1  Prediction   FEV1_est  FEV1/FVC_est  Diagnosis  FEV1  \\\n",
      "0    0.038800  0.961200           1  94.114609     93.413284          0  3.96   \n",
      "1    0.986024  0.013976           0  91.937126     93.013824          1  1.90   \n",
      "2    0.999121  0.000879           0  91.749153     91.928444          0  3.14   \n",
      "3    0.951940  0.048061           0  91.003838     92.165176          0  4.73   \n",
      "4    0.977477  0.022523           0  93.978760     89.702354          0  2.95   \n",
      "..        ...       ...         ...        ...           ...        ...   ...   \n",
      "116  0.372498  0.627502           1  97.644272     92.902016          0  3.10   \n",
      "117  0.519609  0.480391           0  95.479813     95.476814          1  2.17   \n",
      "118  0.250338  0.749662           1  98.962555     91.940643          1  2.69   \n",
      "119  0.452085  0.547915           1  97.012512     93.420586          0  3.46   \n",
      "120  0.559358  0.440642           0  92.707169     91.870407          0  3.39   \n",
      "\n",
      "      FEV1/FVC  FEF2575  FEV1_pred  FEV1/FVC_pred  FEF2575_pred     ID  Trial  \\\n",
      "0    49.900002     0.99       93.0           62.0         110.0   28.0    3.0   \n",
      "1    87.599998     2.35       99.0          101.0         103.0   40.0    1.0   \n",
      "2    80.300003     3.15      105.0           97.0          98.0   16.0    1.0   \n",
      "3    76.000000     3.53      103.0           91.0          74.0   94.0    1.0   \n",
      "4    84.000000     2.98       91.0           98.0          83.0   52.0    2.0   \n",
      "..         ...      ...        ...            ...           ...    ...    ...   \n",
      "116  77.300003     2.83       97.0           94.0          88.0   98.0    2.0   \n",
      "117  82.199997     2.39      107.0           82.0         102.0  223.0    2.0   \n",
      "118  86.500000     3.34       92.0           97.0          94.0  147.0    1.0   \n",
      "119  84.800003     3.79       93.0          101.0          91.0   39.0    4.0   \n",
      "120  80.500000     3.44       90.0           92.0          84.0  123.0    1.0   \n",
      "\n",
      "           Age  Sex      Height      Weight  \n",
      "0    38.700001  1.0  177.800003   87.500000  \n",
      "1    10.900000  1.0  135.300003   30.900000  \n",
      "2    36.500000  0.0  160.000000   84.300003  \n",
      "3    24.700001  1.0  177.800003   90.000000  \n",
      "4    25.100000  0.0  162.000000   80.000000  \n",
      "..         ...  ...         ...         ...  \n",
      "116   0.200000  0.0  167.639999   60.000000  \n",
      "117  66.800003  0.0  160.100006   62.599998  \n",
      "118  13.600000  0.0  158.399994   50.200001  \n",
      "119  28.299999  1.0  175.259995  102.500000  \n",
      "120  17.299999  0.0  175.600006   92.599998  \n",
      "\n",
      "[121 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n",
    "print(metrics_df.mean(axis=0))\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74df0177-018f-4383-a543-ee497c4e2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1.2\n",
      "1      1.2\n",
      "2      1.2\n",
      "3      1.2\n",
      "4      1.2\n",
      "      ... \n",
      "116    1.2\n",
      "117    1.2\n",
      "118    1.2\n",
      "119    1.2\n",
      "120    1.2\n",
      "Name: 0, Length: 121, dtype: float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "set_trace() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12592/2934860890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mPdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_neg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: set_trace() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "idx_pos = predictions_df['Prediction']==predictions_df['Diagnosis']\n",
    "preds_pos = predictions_df.loc[idx_pos,:]\n",
    "idx_neg = predictions_df['Prediction']!=predictions_df['Diagnosis']\n",
    "preds_neg = predictions_df.loc[idx_neg,:]\n",
    "for i in range(len(dataset)):\n",
    "    print(dataset.data_raw[i])\n",
    "    Pdb.set_trace()\n",
    "print(preds_neg.mean(axis=0))\n",
    "plt.hist(predictions_df['Age'])\n",
    "plt.show()\n",
    "plt.hist(preds_neg['Age'])\n",
    "plt.show()\n",
    "os.makedirs('outputs', exist_ok=True)  \n",
    "preds_neg.to_csv('outputs/preds_neg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd019e0-ed00-4763-95ed-abddf614e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
